{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction:\n",
    "You can use this ipython notebook as a template for the rest of the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Basic Useful Setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Basic setups\n",
    "import sys\n",
    "sys.path.append('./models/')\n",
    "# Enable automatic reload of libraries\n",
    "%load_ext autoreload\n",
    "# All modules are reloaded before every comment\n",
    "%autoreload 2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read MNIST using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (60000, 28, 28, 1))\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "from utils import load_mnist\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (\n",
    "    Conv2D, BatchNormalization,\n",
    "    MaxPooling2D, ZeroPadding2D, AveragePooling2D,\n",
    "    add, Dense, Flatten\n",
    ")\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "def resnet(input_tensor):\n",
    "    def name_builder(type, stage, block, name):\n",
    "        return \"{}{}{}_branch{}\".format(type, stage, block, name)\n",
    "    def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "        F1, F2, F3 = filters\n",
    "\n",
    "        def name_fn(type, name):\n",
    "            return name_builder(type, stage, block, name)\n",
    "\n",
    "        x = Conv2D(F1, (1, 1), name=name_fn('res', '2a'))(input_tensor)\n",
    "        x = BatchNormalization(name=name_fn('bn', '2a'))(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        x = Conv2D(F2, kernel_size, padding='same', name=name_fn('res', '2b'))(x)\n",
    "        x = BatchNormalization(name=name_fn('bn', '2b'))(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        x = Conv2D(F3, (1, 1), name=name_fn('res', '2c'))(x)\n",
    "        x = BatchNormalization(name=name_fn('bn', '2c'))(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        x = add([x, input_tensor])\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "        def name_fn(type, name):\n",
    "            return name_builder(type, stage, block, name)\n",
    "\n",
    "        F1, F2, F3 = filters\n",
    "\n",
    "        x = Conv2D(F1, (1, 1), strides=strides, name=name_fn(\"res\", \"2a\"))(input_tensor)\n",
    "        x = BatchNormalization(name=name_fn(\"bn\", \"2a\"))(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        x = Conv2D(F2, kernel_size, padding='same', name=name_fn(\"res\", \"2b\"))(x)\n",
    "        x = BatchNormalization(name=name_fn(\"bn\", \"2b\"))(x)\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        x = Conv2D(F3, (1, 1), name=name_fn(\"res\", \"2c\"))(x)\n",
    "        x = BatchNormalization(name=name_fn(\"bn\", \"2c\"))(x)\n",
    "\n",
    "        sc = Conv2D(F3, (1, 1), strides=strides, name=name_fn(\"res\", \"1\"))(input_tensor)\n",
    "        sc = BatchNormalization(name=name_fn(\"bn\", \"1\"))(sc)\n",
    "\n",
    "        x = add([x, sc])\n",
    "        x = PReLU()(x)\n",
    "\n",
    "        return x\n",
    "    net = ZeroPadding2D((3, 3))(input_tensor)\n",
    "    net = Conv2D(64, (7, 7), strides=(2, 2), name=\"conv1\")(net)\n",
    "    net = BatchNormalization(name=\"bn_conv1\")(net)\n",
    "    net = PReLU()(net)\n",
    "    net = MaxPooling2D((3, 3), strides=(2, 2))(net)\n",
    "\n",
    "    net = conv_block(net, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    net = identity_block(net, 3, [64, 64, 256], stage=2, block='b')\n",
    "    net = identity_block(net, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    net = conv_block(net, 3, [128, 128, 512], stage=3, block='a')\n",
    "    net = identity_block(net, 3, [128, 128, 512], stage=3, block='b')\n",
    "    net = identity_block(net, 3, [128, 128, 512], stage=3, block='c')\n",
    "    net = identity_block(net, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    net = conv_block(net, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    net = identity_block(net, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    net = identity_block(net, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    net = identity_block(net, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    net = identity_block(net, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    net = identity_block(net, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    net = AveragePooling2D((2, 2))(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(10, activation=\"softmax\", name=\"softmax\")(net)\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "X = Input(shape=[28, 28, 1])\n",
    "y = resnet(X)\n",
    "model = Model(X, y, name=\"resnet\")\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and Evaluate LeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.1863 - acc: 0.9461\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 44s 730us/step - loss: 0.0657 - acc: 0.9815\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 43s 719us/step - loss: 0.0358 - acc: 0.9892\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 45s 743us/step - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 46s 767us/step - loss: 0.0220 - acc: 0.9931\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 46s 761us/step - loss: 0.0224 - acc: 0.9928\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 45s 753us/step - loss: 0.0185 - acc: 0.9940\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 45s 744us/step - loss: 0.0189 - acc: 0.9940\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 45s 755us/step - loss: 0.0147 - acc: 0.9952\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 46s 765us/step - loss: 0.0199 - acc: 0.99400s - loss: 0.0197 - acc: 0.994\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.0346 - acc: 0.9893\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 43s 719us/step - loss: 0.0202 - acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCH = 12\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 0.02614428688850312)\n",
      "('Test accuracy:', 0.9929)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02614428688850312, 0.9929]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
